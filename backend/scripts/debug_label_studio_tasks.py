"""
è°ƒè¯•è„šæœ¬ï¼šæ£€æŸ¥æ¨é€åˆ° Label Studio çš„ä»»åŠ¡æ•°æ®ç»“æ„
"""
import os
import sys
import django

# è®¾ç½® Django ç¯å¢ƒ
sys.path.append('/app')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')
django.setup()

from api.models import OcrDocument
from api.views import _generate_ls_tasks
import json

def check_task_generation():
    """æ£€æŸ¥ä»»åŠ¡ç”Ÿæˆé€»è¾‘"""
    print("=" * 80)
    print("Label Studio ä»»åŠ¡æ•°æ®è¯Šæ–­")
    print("=" * 80)
    
    # è·å–æœ€è¿‘çš„æ–‡æ¡£
    docs = OcrDocument.objects.filter(status='processed').order_by('-created_at')[:3]
    
    if not docs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å·²å¤„ç†çš„æ–‡æ¡£")
        return
    
    for doc in docs:
        print(f"\næ–‡æ¡£ ID: {doc.id}")
        print(f"æ–‡ä»¶å: {doc.original_pdf_path}")
        print(f"çŠ¶æ€: {doc.status}")
        print(f"Label Studio åŒæ­¥: {doc.label_studio_synced}")
        print(f"ä»»åŠ¡ IDs: {doc.label_studio_task_ids}")
        print("-" * 80)
        
        # æ£€æŸ¥åŸå§‹ OCR JSON
        if not doc.raw_ocr_json:
            print("âŒ raw_ocr_json ä¸ºç©º")
            continue
        
        ocr_data = doc.raw_ocr_json
        pdf_info = ocr_data.get('pdf_info', [])
        print(f"âœ… PDF ä¿¡æ¯: {len(pdf_info)} é¡µ")
        
        if not pdf_info:
            print("âŒ pdf_info ä¸ºç©º")
            continue
        
        # æ£€æŸ¥ç¬¬ä¸€é¡µçš„æ•°æ®ç»“æ„
        first_page = pdf_info[0]
        print(f"\nç¬¬ä¸€é¡µæ•°æ®ç»“æ„:")
        print(f"  - page_idx: {first_page.get('page_idx')}")
        print(f"  - page_size: {first_page.get('page_size')}")
        print(f"  - para_blocks: {len(first_page.get('para_blocks', []))} ä¸ª")
        print(f"  - preproc_blocks: {len(first_page.get('preproc_blocks', []))} ä¸ª")
        
        # æ£€æŸ¥ blocks å†…å®¹
        all_blocks = first_page.get('para_blocks', []) + first_page.get('preproc_blocks', [])
        if all_blocks:
            print(f"\nç¤ºä¾‹ block:")
            sample_block = all_blocks[0]
            print(f"  - type: {sample_block.get('type')}")
            print(f"  - bbox: {sample_block.get('bbox')}")
            print(f"  - lines: {len(sample_block.get('lines', []))} è¡Œ")
            if sample_block.get('lines'):
                sample_line = sample_block['lines'][0]
                print(f"  - ç¬¬ä¸€è¡Œ bbox: {sample_line.get('bbox')}")
                print(f"  - ç¬¬ä¸€è¡Œ spans: {len(sample_line.get('spans', []))} ä¸ª")
                if sample_line.get('spans'):
                    sample_span = sample_line['spans'][0]
                    print(f"  - ç¬¬ä¸€ä¸ª span content: {sample_span.get('content', '')[:50]}...")
        
        # å°è¯•ç”Ÿæˆä»»åŠ¡
        try:
            # ä» mineru_json_path è·å–å”¯ä¸€æ–‡ä»¶å¤¹å
            mineru_path = doc.mineru_json_path
            if mineru_path:
                import re
                match = re.search(r'mineru_output[/\\]([^/\\]+)', mineru_path)
                if match:
                    unique_folder_name = match.group(1)
                else:
                    print("âŒ æ— æ³•ä»è·¯å¾„æå–æ–‡ä»¶å¤¹å")
                    continue
            else:
                print("âŒ mineru_json_path ä¸ºç©º")
                continue
            
            print(f"\nç”Ÿæˆä»»åŠ¡æ•°æ® (folder: {unique_folder_name})...")
            tasks_data = _generate_ls_tasks(ocr_data, doc, unique_folder_name)
            
            print(f"âœ… ç”Ÿæˆäº† {len(tasks_data)} ä¸ªä»»åŠ¡")
            
            if tasks_data:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªä»»åŠ¡çš„ç»“æ„
                first_task = tasks_data[0]
                print(f"\nç¬¬ä¸€ä¸ªä»»åŠ¡æ•°æ®ç»“æ„:")
                print(f"  - data.image: {first_task['data']['image']}")
                print(f"  - data.page_num: {first_task['data']['page_num']}")
                print(f"  - predictions æ•°é‡: {len(first_task['predictions'])}")
                
                if first_task['predictions']:
                    first_pred = first_task['predictions'][0]
                    result_count = len(first_pred.get('result', []))
                    print(f"  - predictions[0].result æ•°é‡: {result_count}")
                    
                    if result_count > 0:
                        print(f"\nâœ… é¢„æ ‡æ³¨æ•°æ®å­˜åœ¨ï¼")
                        # æ˜¾ç¤ºå‰3ä¸ªæ ‡æ³¨
                        for i, item in enumerate(first_pred['result'][:3]):
                            print(f"\n  æ ‡æ³¨ {i+1}:")
                            print(f"    - from_name: {item.get('from_name')}")
                            print(f"    - type: {item.get('type')}")
                            if item.get('type') == 'rectanglelabels':
                                print(f"    - labels: {item.get('value', {}).get('rectanglelabels')}")
                                print(f"    - bbox: x={item['value']['x']:.1f}, y={item['value']['y']:.1f}, w={item['value']['width']:.1f}, h={item['value']['height']:.1f}")
                            elif item.get('type') == 'textarea':
                                text = item.get('value', {}).get('text', [''])[0]
                                print(f"    - text: {text[:50]}...")
                    else:
                        print(f"\nâŒ predictions[0].result ä¸ºç©ºï¼æ²¡æœ‰ç”Ÿæˆé¢„æ ‡æ³¨")
                else:
                    print(f"\nâŒ predictions ä¸ºç©º")
                
                # ä¿å­˜ç¤ºä¾‹ä»»åŠ¡åˆ°æ–‡ä»¶
                sample_file = f"/tmp/label_studio_task_sample_doc_{doc.id}.json"
                with open(sample_file, 'w', encoding='utf-8') as f:
                    json.dump(first_task, f, indent=2, ensure_ascii=False)
                print(f"\nğŸ’¾ ç¤ºä¾‹ä»»åŠ¡å·²ä¿å­˜åˆ°: {sample_file}")
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "=" * 80)

if __name__ == '__main__':
    check_task_generation()
